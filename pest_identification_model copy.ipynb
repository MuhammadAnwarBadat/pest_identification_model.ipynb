{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input\n",
    "from tensorflow.keras.applications.resnet import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, auc\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ResNet50 base model\n",
    "base_model = ResNet50(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of classes dynamically based on training data or set statically\n",
    "num_classes = 6 \n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5400 images belonging to 6 classes.\n",
      "Found 600 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data preparation\n",
    "train_dir = '/content/drive/MyDrive/datasetip06/test' # please define your own path here\n",
    "val_dir = '/content/drive/MyDrive/datasetip06/test' # please define your own path here\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "168/168 [==============================] - 672s 4s/step - loss: 1.4371 - accuracy: 0.4745 - val_loss: 2.0817 - val_accuracy: 0.1667\n",
      "Epoch 2/100\n",
      "168/168 [==============================] - 541s 3s/step - loss: 1.0906 - accuracy: 0.5913 - val_loss: 2.0545 - val_accuracy: 0.1632\n",
      "Epoch 3/100\n",
      "168/168 [==============================] - 540s 3s/step - loss: 0.9827 - accuracy: 0.6379 - val_loss: 2.0809 - val_accuracy: 0.1771\n",
      "Epoch 4/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.9000 - accuracy: 0.6606 - val_loss: 1.9553 - val_accuracy: 0.3021\n",
      "Epoch 5/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.8445 - accuracy: 0.6943 - val_loss: 1.9929 - val_accuracy: 0.4045\n",
      "Epoch 6/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.7696 - accuracy: 0.7137 - val_loss: 1.4460 - val_accuracy: 0.5260\n",
      "Epoch 7/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.7487 - accuracy: 0.7189 - val_loss: 1.4224 - val_accuracy: 0.4722\n",
      "Epoch 8/100\n",
      "168/168 [==============================] - 538s 3s/step - loss: 0.7262 - accuracy: 0.7299 - val_loss: 2.5128 - val_accuracy: 0.4062\n",
      "Epoch 9/100\n",
      "168/168 [==============================] - 538s 3s/step - loss: 0.6683 - accuracy: 0.7517 - val_loss: 1.5335 - val_accuracy: 0.5399\n",
      "Epoch 10/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.6462 - accuracy: 0.7520 - val_loss: 3.0411 - val_accuracy: 0.4861\n",
      "Epoch 11/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.6423 - accuracy: 0.7651 - val_loss: 0.9739 - val_accuracy: 0.6580\n",
      "Epoch 12/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.6257 - accuracy: 0.7645 - val_loss: 1.1707 - val_accuracy: 0.6128\n",
      "Epoch 13/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.5981 - accuracy: 0.7693 - val_loss: 0.9534 - val_accuracy: 0.6632\n",
      "Epoch 14/100\n",
      "168/168 [==============================] - 538s 3s/step - loss: 0.5905 - accuracy: 0.7697 - val_loss: 1.0307 - val_accuracy: 0.6250\n",
      "Epoch 15/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.5695 - accuracy: 0.7874 - val_loss: 1.4749 - val_accuracy: 0.5260\n",
      "Epoch 16/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.5399 - accuracy: 0.7964 - val_loss: 1.3439 - val_accuracy: 0.5660\n",
      "Epoch 17/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.5012 - accuracy: 0.8100 - val_loss: 1.3882 - val_accuracy: 0.5781\n",
      "Epoch 18/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.5013 - accuracy: 0.8094 - val_loss: 1.5168 - val_accuracy: 0.5156\n",
      "Epoch 19/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.4923 - accuracy: 0.8096 - val_loss: 0.9815 - val_accuracy: 0.6667\n",
      "Epoch 20/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.4701 - accuracy: 0.8204 - val_loss: 0.9382 - val_accuracy: 0.7014\n",
      "Epoch 21/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.4740 - accuracy: 0.8212 - val_loss: 1.4077 - val_accuracy: 0.5521\n",
      "Epoch 22/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.4358 - accuracy: 0.8366 - val_loss: 1.3997 - val_accuracy: 0.5017\n",
      "Epoch 23/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.4538 - accuracy: 0.8266 - val_loss: 1.3171 - val_accuracy: 0.5226\n",
      "Epoch 24/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.4264 - accuracy: 0.8383 - val_loss: 1.4947 - val_accuracy: 0.5955\n",
      "Epoch 25/100\n",
      "168/168 [==============================] - 540s 3s/step - loss: 0.4022 - accuracy: 0.8465 - val_loss: 1.8550 - val_accuracy: 0.5694\n",
      "Epoch 26/100\n",
      "168/168 [==============================] - 540s 3s/step - loss: 0.4074 - accuracy: 0.8422 - val_loss: 0.8920 - val_accuracy: 0.6910\n",
      "Epoch 27/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.3918 - accuracy: 0.8458 - val_loss: 0.9732 - val_accuracy: 0.6962\n",
      "Epoch 28/100\n",
      "168/168 [==============================] - 540s 3s/step - loss: 0.3881 - accuracy: 0.8530 - val_loss: 0.9650 - val_accuracy: 0.6875\n",
      "Epoch 29/100\n",
      "168/168 [==============================] - 541s 3s/step - loss: 0.3738 - accuracy: 0.8584 - val_loss: 0.8971 - val_accuracy: 0.6927\n",
      "Epoch 30/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.3518 - accuracy: 0.8659 - val_loss: 1.2223 - val_accuracy: 0.6059\n",
      "Epoch 31/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.3553 - accuracy: 0.8653 - val_loss: 0.9868 - val_accuracy: 0.6997\n",
      "Epoch 32/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.3457 - accuracy: 0.8653 - val_loss: 0.9409 - val_accuracy: 0.6615\n",
      "Epoch 33/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.3181 - accuracy: 0.8756 - val_loss: 1.1505 - val_accuracy: 0.6632\n",
      "Epoch 34/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.3228 - accuracy: 0.8752 - val_loss: 1.0131 - val_accuracy: 0.6354\n",
      "Epoch 35/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.3130 - accuracy: 0.8811 - val_loss: 0.9403 - val_accuracy: 0.6892\n",
      "Epoch 36/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.2790 - accuracy: 0.8944 - val_loss: 1.0708 - val_accuracy: 0.6528\n",
      "Epoch 37/100\n",
      "168/168 [==============================] - 538s 3s/step - loss: 0.2925 - accuracy: 0.8886 - val_loss: 1.2429 - val_accuracy: 0.7292\n",
      "Epoch 38/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.2651 - accuracy: 0.8929 - val_loss: 1.3300 - val_accuracy: 0.6510\n",
      "Epoch 39/100\n",
      "168/168 [==============================] - 540s 3s/step - loss: 0.2739 - accuracy: 0.9015 - val_loss: 1.3744 - val_accuracy: 0.6441\n",
      "Epoch 40/100\n",
      "168/168 [==============================] - 540s 3s/step - loss: 0.2564 - accuracy: 0.9001 - val_loss: 1.4550 - val_accuracy: 0.6024\n",
      "Epoch 41/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.2763 - accuracy: 0.8938 - val_loss: 1.1329 - val_accuracy: 0.7049\n",
      "Epoch 42/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.2609 - accuracy: 0.9029 - val_loss: 1.1883 - val_accuracy: 0.6632\n",
      "Epoch 43/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.2419 - accuracy: 0.9069 - val_loss: 0.9511 - val_accuracy: 0.7205\n",
      "Epoch 44/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.2404 - accuracy: 0.9074 - val_loss: 1.0600 - val_accuracy: 0.7170\n",
      "Epoch 45/100\n",
      "168/168 [==============================] - 540s 3s/step - loss: 0.2341 - accuracy: 0.9106 - val_loss: 1.5514 - val_accuracy: 0.5903\n",
      "Epoch 46/100\n",
      "168/168 [==============================] - 540s 3s/step - loss: 0.2413 - accuracy: 0.9087 - val_loss: 1.7743 - val_accuracy: 0.6111\n",
      "Epoch 47/100\n",
      "168/168 [==============================] - 540s 3s/step - loss: 0.2137 - accuracy: 0.9178 - val_loss: 0.9383 - val_accuracy: 0.7170\n",
      "Epoch 48/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.2100 - accuracy: 0.9195 - val_loss: 2.0879 - val_accuracy: 0.5660\n",
      "Epoch 49/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.2037 - accuracy: 0.9223 - val_loss: 2.6770 - val_accuracy: 0.6146\n",
      "Epoch 50/100\n",
      "168/168 [==============================] - 540s 3s/step - loss: 0.2057 - accuracy: 0.9192 - val_loss: 1.2994 - val_accuracy: 0.6701\n",
      "Epoch 51/100\n",
      "168/168 [==============================] - 538s 3s/step - loss: 0.1748 - accuracy: 0.9311 - val_loss: 1.1791 - val_accuracy: 0.6806\n",
      "Epoch 52/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.1996 - accuracy: 0.9270 - val_loss: 1.3947 - val_accuracy: 0.5851\n",
      "Epoch 53/100\n",
      "168/168 [==============================] - 540s 3s/step - loss: 0.1911 - accuracy: 0.9283 - val_loss: 1.4133 - val_accuracy: 0.6806\n",
      "Epoch 54/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.1981 - accuracy: 0.9257 - val_loss: 1.2002 - val_accuracy: 0.6997\n",
      "Epoch 55/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.1560 - accuracy: 0.9385 - val_loss: 1.1515 - val_accuracy: 0.7309\n",
      "Epoch 56/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.1704 - accuracy: 0.9355 - val_loss: 1.4872 - val_accuracy: 0.5833\n",
      "Epoch 57/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.1666 - accuracy: 0.9382 - val_loss: 1.8403 - val_accuracy: 0.6545\n",
      "Epoch 58/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.1805 - accuracy: 0.9367 - val_loss: 1.1063 - val_accuracy: 0.7066\n",
      "Epoch 59/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.1629 - accuracy: 0.9378 - val_loss: 1.4312 - val_accuracy: 0.6424\n",
      "Epoch 60/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.1763 - accuracy: 0.9361 - val_loss: 1.2934 - val_accuracy: 0.7049\n",
      "Epoch 61/100\n",
      "168/168 [==============================] - 540s 3s/step - loss: 0.1648 - accuracy: 0.9374 - val_loss: 1.4211 - val_accuracy: 0.7153\n",
      "Epoch 62/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.1573 - accuracy: 0.9437 - val_loss: 1.3397 - val_accuracy: 0.7274\n",
      "Epoch 63/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.1365 - accuracy: 0.9514 - val_loss: 1.3477 - val_accuracy: 0.7101\n",
      "Epoch 64/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.1445 - accuracy: 0.9484 - val_loss: 1.1982 - val_accuracy: 0.7083\n",
      "Epoch 65/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.1280 - accuracy: 0.9508 - val_loss: 1.3425 - val_accuracy: 0.7292\n",
      "Epoch 66/100\n",
      "168/168 [==============================] - 540s 3s/step - loss: 0.1563 - accuracy: 0.9447 - val_loss: 1.4132 - val_accuracy: 0.7205\n",
      "Epoch 67/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.1500 - accuracy: 0.9452 - val_loss: 1.6805 - val_accuracy: 0.6736\n",
      "Epoch 68/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.1387 - accuracy: 0.9534 - val_loss: 2.0840 - val_accuracy: 0.5868\n",
      "Epoch 69/100\n",
      "168/168 [==============================] - 540s 3s/step - loss: 0.1462 - accuracy: 0.9456 - val_loss: 1.5716 - val_accuracy: 0.6684\n",
      "Epoch 70/100\n",
      "168/168 [==============================] - 540s 3s/step - loss: 0.1370 - accuracy: 0.9521 - val_loss: 1.5596 - val_accuracy: 0.6667\n",
      "Epoch 71/100\n",
      "168/168 [==============================] - 540s 3s/step - loss: 0.1108 - accuracy: 0.9577 - val_loss: 3.6834 - val_accuracy: 0.5174\n",
      "Epoch 72/100\n",
      "168/168 [==============================] - 540s 3s/step - loss: 0.1214 - accuracy: 0.9527 - val_loss: 1.2531 - val_accuracy: 0.7292\n",
      "Epoch 73/100\n",
      "168/168 [==============================] - 540s 3s/step - loss: 0.1089 - accuracy: 0.9590 - val_loss: 1.4954 - val_accuracy: 0.7205\n",
      "Epoch 74/100\n",
      "168/168 [==============================] - 540s 3s/step - loss: 0.1364 - accuracy: 0.9503 - val_loss: 1.3578 - val_accuracy: 0.7431\n",
      "Epoch 75/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.1193 - accuracy: 0.9568 - val_loss: 1.4838 - val_accuracy: 0.7396\n",
      "Epoch 76/100\n",
      "168/168 [==============================] - 540s 3s/step - loss: 0.1113 - accuracy: 0.9562 - val_loss: 2.6081 - val_accuracy: 0.5556\n",
      "Epoch 77/100\n",
      "168/168 [==============================] - 540s 3s/step - loss: 0.1216 - accuracy: 0.9549 - val_loss: 1.7414 - val_accuracy: 0.6059\n",
      "Epoch 78/100\n",
      "168/168 [==============================] - 539s 3s/step - loss: 0.1231 - accuracy: 0.9536 - val_loss: 1.4008 - val_accuracy: 0.7170\n",
      "Epoch 79/100\n",
      "168/168 [==============================] - 540s 3s/step - loss: 0.1057 - accuracy: 0.9613 - val_loss: 1.6387 - val_accuracy: 0.7014\n",
      "Epoch 80/100\n",
      "168/168 [==============================] - 540s 3s/step - loss: 0.1031 - accuracy: 0.9618 - val_loss: 1.4258 - val_accuracy: 0.7413\n",
      "Epoch 81/100\n",
      "168/168 [==============================] - 540s 3s/step - loss: 0.1186 - accuracy: 0.9590 - val_loss: 1.6307 - val_accuracy: 0.6840\n",
      "Epoch 82/100\n",
      "168/168 [==============================] - 540s 3s/step - loss: 0.1017 - accuracy: 0.9627 - val_loss: 1.1549 - val_accuracy: 0.7483\n",
      "Epoch 83/100\n",
      "168/168 [==============================] - 540s 3s/step - loss: 0.1016 - accuracy: 0.9650 - val_loss: 1.7063 - val_accuracy: 0.6806\n",
      "Epoch 84/100\n",
      "168/168 [==============================] - 541s 3s/step - loss: 0.1238 - accuracy: 0.9542 - val_loss: 1.5008 - val_accuracy: 0.7257\n",
      "Epoch 85/100\n",
      "168/168 [==============================] - 541s 3s/step - loss: 0.0972 - accuracy: 0.9640 - val_loss: 1.3643 - val_accuracy: 0.7326\n",
      "Epoch 86/100\n",
      "168/168 [==============================] - 540s 3s/step - loss: 0.0892 - accuracy: 0.9657 - val_loss: 1.7991 - val_accuracy: 0.6927\n",
      "Epoch 87/100\n",
      "168/168 [==============================] - 540s 3s/step - loss: 0.1236 - accuracy: 0.9555 - val_loss: 3.4297 - val_accuracy: 0.5174\n",
      "Epoch 88/100\n",
      "103/168 [=================>............] - ETA: 3:23 - loss: 0.0851 - accuracy: 0.9699"
     ]
    }
   ],
   "source": [
    "# Model training\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=5399 // 32,  # Adjust based on your dataset\n",
    "    epochs= 100,  # Updated as suggested\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=600 // 32)  # Adjust based on your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = Model(inputs=base_model.input, outputs=x)  # x is the output of the last Dense layer before predictions\n",
    "\n",
    "# Function to calculate prototypes\n",
    "def calculate_prototypes(embedding_model, data_generator, num_classes):\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    for images, label in data_generator:\n",
    "        # Predict to get embeddings\n",
    "        emb = embedding_model.predict(images)\n",
    "        embeddings.append(emb)\n",
    "        labels.append(label)\n",
    "\n",
    "    embeddings = np.vstack(embeddings)\n",
    "    labels = np.vstack(labels)\n",
    "\n",
    "    prototypes = []\n",
    "    for i in range(num_classes):  # Assuming num_classes is defined\n",
    "        class_embeddings = embeddings[np.argmax(labels, axis=1) == i]\n",
    "        prototype = np.mean(class_embeddings, axis=0)\n",
    "        prototypes.append(prototype)\n",
    "\n",
    "    return np.array(prototypes)\n",
    "\n",
    "# Function for distance entropy calculation\n",
    "def distance_entropy(prototypes, embeddings):\n",
    "    distances = np.sqrt(((embeddings[:, np.newaxis, :] - prototypes[np.newaxis, :, :]) ** 2).sum(axis=2))\n",
    "    softmax_distances = np.exp(-distances) / np.exp(-distances).sum(axis=1, keepdims=True)\n",
    "    entropy = -np.sum(softmax_distances * np.log(softmax_distances + 1e-5), axis=1)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proto_de(features, labels):\n",
    "    # Calculate the prototype (mean feature vector) for each class\n",
    "    class_prototypes = {}\n",
    "    for label in np.unique(labels):\n",
    "        class_indices = np.where(labels == label)[0]\n",
    "        class_features = features[class_indices]\n",
    "        class_prototypes[label] = np.mean(class_features, axis=0)\n",
    "    \n",
    "    # Calculate the distance from each feature vector to its class prototype\n",
    "    distances = []\n",
    "    for feature, label in zip(features, labels):\n",
    "        prototype = class_prototypes[label]\n",
    "        distance = np.linalg.norm(feature - prototype)\n",
    "        distances.append(distance)\n",
    "    \n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bound_de(model, features, labels):\n",
    "    decision_scores = model.predict(features)  # Assuming this returns a score reflecting distance from decision boundary\n",
    "    distances = np.abs(0.5 - decision_scores)  # Assuming scores are probabilities in [0, 1] for binary classification\n",
    "    \n",
    "    return distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_branch_selection(proto_scores, bound_scores, top_k):\n",
    "    # Combine Proto-DE and Bound-DE scores\n",
    "    # A simple approach could be averaging the scores\n",
    "    combined_scores = (np.array(proto_scores) + np.array(bound_scores)) / 2\n",
    "    \n",
    "    selected_indices = np.argsort(combined_scores)[-top_k:]\n",
    "    \n",
    "    return selected_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_selection(model, train_data, train_labels, epochs=10, batch_size=32, top_k=100):\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        \n",
    "        # Step 1: Feature Extraction\n",
    "        features = extract_features(model, train_data)\n",
    "        \n",
    "        # Step 2: Calculate Proto-DE and Bound-DE scores\n",
    "        proto_scores = proto_de(features, train_labels)\n",
    "        bound_scores = bound_de(model, features, train_labels)\n",
    "        \n",
    "        # Step 3: Select samples using Multi-Branch selection\n",
    "        selected_indices = multi_branch_selection(proto_scores, bound_scores, top_k=top_k)\n",
    "        selected_data = train_data[selected_indices]\n",
    "        selected_labels = train_labels[selected_indices]\n",
    "        \n",
    "        # Step 4: Train on selected samples\n",
    "        model.fit(selected_data, selected_labels, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting training results with specified colors\n",
    "plt.plot(history.history['accuracy'], color='darkblue', label='Proto-DE-Good')\n",
    "plt.plot(history.history['val_accuracy'], color='orange', label='Proto-DE-Bad')\n",
    "plt.plot(history.history['val_loss'], color='gray', label='Bound-DE-Good')\n",
    "plt.plot(history.history['loss'], color='yellow', label='Bound-DE-Bad')\n",
    "plt.plot(history.history['val_loss'], color='lightblue', label='Multi-Branch-Good')\n",
    "plt.plot(history.history['loss'], color='green', label='Multi-Branch-Bad')\n",
    "\n",
    "plt.title('Test accuracy when selecting different samples using different methods')\n",
    "plt.xlabel('Test Accuracy')\n",
    "plt.ylabel('Select Percentage')\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), shadow=True, ncol=3)\n",
    "\n",
    "# Adjusting legends alignment\n",
    "plt.subplots_adjust(bottom=0.15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
